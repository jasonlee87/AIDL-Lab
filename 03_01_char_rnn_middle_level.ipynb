{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_01_char_rnn_middle-level.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonlee87/AIDL-Lab/blob/master/03_01_char_rnn_middle_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlPjrgINiHg0",
        "colab_type": "code",
        "outputId": "8ff34665-5b5a-4ec7-fc70-81521869c7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrg9HmF9b_dk",
        "colab_type": "code",
        "outputId": "817f545e-0793-4b01-bb34-2db8426f7e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X9j1zSGcawW",
        "colab_type": "code",
        "outputId": "bfe96305-cb74-4dae-a10d-7799050de8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Nov 22 14:26 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 22 14:19 ..\n",
            "drwxr-xr-x 1 root root 4096 Nov 20 16:17 .config\n",
            "drwx------ 4 root root 4096 Nov 22 14:26 drive\n",
            "drwxr-xr-x 1 root root 4096 Nov 15 16:31 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KVsYmlmclHR",
        "colab_type": "code",
        "outputId": "9f49e1eb-a1e2-4c97-b2bd-a743abadf5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My Drive/dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rbvB4nb6joy",
        "colab_type": "text"
      },
      "source": [
        "### Sing a Song of Sixpence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp6ym_XR6pVv",
        "colab_type": "text"
      },
      "source": [
        "Load Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eF88_g3XpNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJM1sUM9bnYm",
        "colab_type": "code",
        "outputId": "e9ff4743-a294-4cfd-f90f-4070aa5f2b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "# load text\n",
        "raw_text = load_doc('rhyme.txt')\n",
        "print(raw_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sing a song of sixpence,\n",
            "A pocket full of rye.\n",
            "Four and twenty blackbirds,\n",
            "Baked in a pie.\n",
            " \n",
            "When the pie was opened\n",
            "The birds began to sing;\n",
            "Wasn't that a dainty dish,\n",
            "To set before the king.\n",
            " \n",
            "The king was in his counting house,\n",
            "Counting out his money;\n",
            "The queen was in the parlour,\n",
            "Eating bread and honey.\n",
            " \n",
            "The maid was in the garden,\n",
            "Hanging out the clothes,\n",
            "When down came a blackbird\n",
            "And pecked off her nose.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCBXlsav6wck",
        "colab_type": "text"
      },
      "source": [
        "Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wxvzcBcYOR",
        "colab_type": "code",
        "outputId": "0e18134e-03ba-4743-df5d-ada9d4db16ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# clean\n",
        "tokens = raw_text.split()\n",
        "raw_text = ' '.join(tokens)\n",
        "print(raw_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sing a song of sixpence, A pocket full of rye. Four and twenty blackbirds, Baked in a pie. When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king. The king was in his counting house, Counting out his money; The queen was in the parlour, Eating bread and honey. The maid was in the garden, Hanging out the clothes, When down came a blackbird And pecked off her nose.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L83y5jBU65mI",
        "colab_type": "text"
      },
      "source": [
        "Create Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDOgSZXoc5p0",
        "colab_type": "code",
        "outputId": "c2aab59e-32d8-4d61-b0b0-e05f2462eb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# organize into sequences of characters\n",
        "length = 10\n",
        "sequences = list()\n",
        "for i in range(length, len(raw_text)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = raw_text[i-length:i+1]\n",
        "\t# store\n",
        "\tsequences.append(seq)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "print(sequences[0])\n",
        "print(sequences[1])\n",
        "print(sequences[397])\n",
        "print(sequences[398])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 399\n",
            "Sing a song\n",
            "ing a song \n",
            "ff her nose\n",
            "f her nose.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHoKZjEYeuzt",
        "colab_type": "text"
      },
      "source": [
        "Save Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqE6BUx3evcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg8xrPB1dVDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save sequences to file\n",
        "out_filename = 'char_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX1moKe3fWI4",
        "colab_type": "text"
      },
      "source": [
        "Complete Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfB3uFYKfZns",
        "colab_type": "code",
        "outputId": "53cb8c35-034a-42f6-bc89-befe2a1b5c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load text\n",
        "char_text = load_doc('char_sequences.txt')\n",
        "print(char_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sing a song\n",
            "ing a song \n",
            "ng a song o\n",
            "g a song of\n",
            " a song of \n",
            "a song of s\n",
            " song of si\n",
            "song of six\n",
            "ong of sixp\n",
            "ng of sixpe\n",
            "g of sixpen\n",
            " of sixpenc\n",
            "of sixpence\n",
            "f sixpence,\n",
            " sixpence, \n",
            "sixpence, A\n",
            "ixpence, A \n",
            "xpence, A p\n",
            "pence, A po\n",
            "ence, A poc\n",
            "nce, A pock\n",
            "ce, A pocke\n",
            "e, A pocket\n",
            ", A pocket \n",
            " A pocket f\n",
            "A pocket fu\n",
            " pocket ful\n",
            "pocket full\n",
            "ocket full \n",
            "cket full o\n",
            "ket full of\n",
            "et full of \n",
            "t full of r\n",
            " full of ry\n",
            "full of rye\n",
            "ull of rye.\n",
            "ll of rye. \n",
            "l of rye. F\n",
            " of rye. Fo\n",
            "of rye. Fou\n",
            "f rye. Four\n",
            " rye. Four \n",
            "rye. Four a\n",
            "ye. Four an\n",
            "e. Four and\n",
            ". Four and \n",
            " Four and t\n",
            "Four and tw\n",
            "our and twe\n",
            "ur and twen\n",
            "r and twent\n",
            " and twenty\n",
            "and twenty \n",
            "nd twenty b\n",
            "d twenty bl\n",
            " twenty bla\n",
            "twenty blac\n",
            "wenty black\n",
            "enty blackb\n",
            "nty blackbi\n",
            "ty blackbir\n",
            "y blackbird\n",
            " blackbirds\n",
            "blackbirds,\n",
            "lackbirds, \n",
            "ackbirds, B\n",
            "ckbirds, Ba\n",
            "kbirds, Bak\n",
            "birds, Bake\n",
            "irds, Baked\n",
            "rds, Baked \n",
            "ds, Baked i\n",
            "s, Baked in\n",
            ", Baked in \n",
            " Baked in a\n",
            "Baked in a \n",
            "aked in a p\n",
            "ked in a pi\n",
            "ed in a pie\n",
            "d in a pie.\n",
            " in a pie. \n",
            "in a pie. W\n",
            "n a pie. Wh\n",
            " a pie. Whe\n",
            "a pie. When\n",
            " pie. When \n",
            "pie. When t\n",
            "ie. When th\n",
            "e. When the\n",
            ". When the \n",
            " When the p\n",
            "When the pi\n",
            "hen the pie\n",
            "en the pie \n",
            "n the pie w\n",
            " the pie wa\n",
            "the pie was\n",
            "he pie was \n",
            "e pie was o\n",
            " pie was op\n",
            "pie was ope\n",
            "ie was open\n",
            "e was opene\n",
            " was opened\n",
            "was opened \n",
            "as opened T\n",
            "s opened Th\n",
            " opened The\n",
            "opened The \n",
            "pened The b\n",
            "ened The bi\n",
            "ned The bir\n",
            "ed The bird\n",
            "d The birds\n",
            " The birds \n",
            "The birds b\n",
            "he birds be\n",
            "e birds beg\n",
            " birds bega\n",
            "birds began\n",
            "irds began \n",
            "rds began t\n",
            "ds began to\n",
            "s began to \n",
            " began to s\n",
            "began to si\n",
            "egan to sin\n",
            "gan to sing\n",
            "an to sing;\n",
            "n to sing; \n",
            " to sing; W\n",
            "to sing; Wa\n",
            "o sing; Was\n",
            " sing; Wasn\n",
            "sing; Wasn'\n",
            "ing; Wasn't\n",
            "ng; Wasn't \n",
            "g; Wasn't t\n",
            "; Wasn't th\n",
            " Wasn't tha\n",
            "Wasn't that\n",
            "asn't that \n",
            "sn't that a\n",
            "n't that a \n",
            "'t that a d\n",
            "t that a da\n",
            " that a dai\n",
            "that a dain\n",
            "hat a daint\n",
            "at a dainty\n",
            "t a dainty \n",
            " a dainty d\n",
            "a dainty di\n",
            " dainty dis\n",
            "dainty dish\n",
            "ainty dish,\n",
            "inty dish, \n",
            "nty dish, T\n",
            "ty dish, To\n",
            "y dish, To \n",
            " dish, To s\n",
            "dish, To se\n",
            "ish, To set\n",
            "sh, To set \n",
            "h, To set b\n",
            ", To set be\n",
            " To set bef\n",
            "To set befo\n",
            "o set befor\n",
            " set before\n",
            "set before \n",
            "et before t\n",
            "t before th\n",
            " before the\n",
            "before the \n",
            "efore the k\n",
            "fore the ki\n",
            "ore the kin\n",
            "re the king\n",
            "e the king.\n",
            " the king. \n",
            "the king. T\n",
            "he king. Th\n",
            "e king. The\n",
            " king. The \n",
            "king. The k\n",
            "ing. The ki\n",
            "ng. The kin\n",
            "g. The king\n",
            ". The king \n",
            " The king w\n",
            "The king wa\n",
            "he king was\n",
            "e king was \n",
            " king was i\n",
            "king was in\n",
            "ing was in \n",
            "ng was in h\n",
            "g was in hi\n",
            " was in his\n",
            "was in his \n",
            "as in his c\n",
            "s in his co\n",
            " in his cou\n",
            "in his coun\n",
            "n his count\n",
            " his counti\n",
            "his countin\n",
            "is counting\n",
            "s counting \n",
            " counting h\n",
            "counting ho\n",
            "ounting hou\n",
            "unting hous\n",
            "nting house\n",
            "ting house,\n",
            "ing house, \n",
            "ng house, C\n",
            "g house, Co\n",
            " house, Cou\n",
            "house, Coun\n",
            "ouse, Count\n",
            "use, Counti\n",
            "se, Countin\n",
            "e, Counting\n",
            ", Counting \n",
            " Counting o\n",
            "Counting ou\n",
            "ounting out\n",
            "unting out \n",
            "nting out h\n",
            "ting out hi\n",
            "ing out his\n",
            "ng out his \n",
            "g out his m\n",
            " out his mo\n",
            "out his mon\n",
            "ut his mone\n",
            "t his money\n",
            " his money;\n",
            "his money; \n",
            "is money; T\n",
            "s money; Th\n",
            " money; The\n",
            "money; The \n",
            "oney; The q\n",
            "ney; The qu\n",
            "ey; The que\n",
            "y; The quee\n",
            "; The queen\n",
            " The queen \n",
            "The queen w\n",
            "he queen wa\n",
            "e queen was\n",
            " queen was \n",
            "queen was i\n",
            "ueen was in\n",
            "een was in \n",
            "en was in t\n",
            "n was in th\n",
            " was in the\n",
            "was in the \n",
            "as in the p\n",
            "s in the pa\n",
            " in the par\n",
            "in the parl\n",
            "n the parlo\n",
            " the parlou\n",
            "the parlour\n",
            "he parlour,\n",
            "e parlour, \n",
            " parlour, E\n",
            "parlour, Ea\n",
            "arlour, Eat\n",
            "rlour, Eati\n",
            "lour, Eatin\n",
            "our, Eating\n",
            "ur, Eating \n",
            "r, Eating b\n",
            ", Eating br\n",
            " Eating bre\n",
            "Eating brea\n",
            "ating bread\n",
            "ting bread \n",
            "ing bread a\n",
            "ng bread an\n",
            "g bread and\n",
            " bread and \n",
            "bread and h\n",
            "read and ho\n",
            "ead and hon\n",
            "ad and hone\n",
            "d and honey\n",
            " and honey.\n",
            "and honey. \n",
            "nd honey. T\n",
            "d honey. Th\n",
            " honey. The\n",
            "honey. The \n",
            "oney. The m\n",
            "ney. The ma\n",
            "ey. The mai\n",
            "y. The maid\n",
            ". The maid \n",
            " The maid w\n",
            "The maid wa\n",
            "he maid was\n",
            "e maid was \n",
            " maid was i\n",
            "maid was in\n",
            "aid was in \n",
            "id was in t\n",
            "d was in th\n",
            " was in the\n",
            "was in the \n",
            "as in the g\n",
            "s in the ga\n",
            " in the gar\n",
            "in the gard\n",
            "n the garde\n",
            " the garden\n",
            "the garden,\n",
            "he garden, \n",
            "e garden, H\n",
            " garden, Ha\n",
            "garden, Han\n",
            "arden, Hang\n",
            "rden, Hangi\n",
            "den, Hangin\n",
            "en, Hanging\n",
            "n, Hanging \n",
            ", Hanging o\n",
            " Hanging ou\n",
            "Hanging out\n",
            "anging out \n",
            "nging out t\n",
            "ging out th\n",
            "ing out the\n",
            "ng out the \n",
            "g out the c\n",
            " out the cl\n",
            "out the clo\n",
            "ut the clot\n",
            "t the cloth\n",
            " the clothe\n",
            "the clothes\n",
            "he clothes,\n",
            "e clothes, \n",
            " clothes, W\n",
            "clothes, Wh\n",
            "lothes, Whe\n",
            "othes, When\n",
            "thes, When \n",
            "hes, When d\n",
            "es, When do\n",
            "s, When dow\n",
            ", When down\n",
            " When down \n",
            "When down c\n",
            "hen down ca\n",
            "en down cam\n",
            "n down came\n",
            " down came \n",
            "down came a\n",
            "own came a \n",
            "wn came a b\n",
            "n came a bl\n",
            " came a bla\n",
            "came a blac\n",
            "ame a black\n",
            "me a blackb\n",
            "e a blackbi\n",
            " a blackbir\n",
            "a blackbird\n",
            " blackbird \n",
            "blackbird A\n",
            "lackbird An\n",
            "ackbird And\n",
            "ckbird And \n",
            "kbird And p\n",
            "bird And pe\n",
            "ird And pec\n",
            "rd And peck\n",
            "d And pecke\n",
            " And pecked\n",
            "And pecked \n",
            "nd pecked o\n",
            "d pecked of\n",
            " pecked off\n",
            "pecked off \n",
            "ecked off h\n",
            "cked off he\n",
            "ked off her\n",
            "ed off her \n",
            "d off her n\n",
            " off her no\n",
            "off her nos\n",
            "ff her nose\n",
            "f her nose.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELQlEX8lgRcl",
        "colab_type": "text"
      },
      "source": [
        "### Train Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQSizX96gZIE",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAHfGoFV89SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils  import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLTyVcKV9SaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LljIW8zI_HXK",
        "colab_type": "code",
        "outputId": "7780418c-ef37-4ed6-94a2-4765c0bd47ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# load\n",
        "in_filename = 'char_sequences.txt'\n",
        "raw_text = load_doc(in_filename)\n",
        "#print (raw_text)\n",
        "\n",
        "lines = raw_text.split('\\n')\n",
        "print (type(lines))\n",
        "print (lines)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['Sing a song', 'ing a song ', 'ng a song o', 'g a song of', ' a song of ', 'a song of s', ' song of si', 'song of six', 'ong of sixp', 'ng of sixpe', 'g of sixpen', ' of sixpenc', 'of sixpence', 'f sixpence,', ' sixpence, ', 'sixpence, A', 'ixpence, A ', 'xpence, A p', 'pence, A po', 'ence, A poc', 'nce, A pock', 'ce, A pocke', 'e, A pocket', ', A pocket ', ' A pocket f', 'A pocket fu', ' pocket ful', 'pocket full', 'ocket full ', 'cket full o', 'ket full of', 'et full of ', 't full of r', ' full of ry', 'full of rye', 'ull of rye.', 'll of rye. ', 'l of rye. F', ' of rye. Fo', 'of rye. Fou', 'f rye. Four', ' rye. Four ', 'rye. Four a', 'ye. Four an', 'e. Four and', '. Four and ', ' Four and t', 'Four and tw', 'our and twe', 'ur and twen', 'r and twent', ' and twenty', 'and twenty ', 'nd twenty b', 'd twenty bl', ' twenty bla', 'twenty blac', 'wenty black', 'enty blackb', 'nty blackbi', 'ty blackbir', 'y blackbird', ' blackbirds', 'blackbirds,', 'lackbirds, ', 'ackbirds, B', 'ckbirds, Ba', 'kbirds, Bak', 'birds, Bake', 'irds, Baked', 'rds, Baked ', 'ds, Baked i', 's, Baked in', ', Baked in ', ' Baked in a', 'Baked in a ', 'aked in a p', 'ked in a pi', 'ed in a pie', 'd in a pie.', ' in a pie. ', 'in a pie. W', 'n a pie. Wh', ' a pie. Whe', 'a pie. When', ' pie. When ', 'pie. When t', 'ie. When th', 'e. When the', '. When the ', ' When the p', 'When the pi', 'hen the pie', 'en the pie ', 'n the pie w', ' the pie wa', 'the pie was', 'he pie was ', 'e pie was o', ' pie was op', 'pie was ope', 'ie was open', 'e was opene', ' was opened', 'was opened ', 'as opened T', 's opened Th', ' opened The', 'opened The ', 'pened The b', 'ened The bi', 'ned The bir', 'ed The bird', 'd The birds', ' The birds ', 'The birds b', 'he birds be', 'e birds beg', ' birds bega', 'birds began', 'irds began ', 'rds began t', 'ds began to', 's began to ', ' began to s', 'began to si', 'egan to sin', 'gan to sing', 'an to sing;', 'n to sing; ', ' to sing; W', 'to sing; Wa', 'o sing; Was', ' sing; Wasn', \"sing; Wasn'\", \"ing; Wasn't\", \"ng; Wasn't \", \"g; Wasn't t\", \"; Wasn't th\", \" Wasn't tha\", \"Wasn't that\", \"asn't that \", \"sn't that a\", \"n't that a \", \"'t that a d\", 't that a da', ' that a dai', 'that a dain', 'hat a daint', 'at a dainty', 't a dainty ', ' a dainty d', 'a dainty di', ' dainty dis', 'dainty dish', 'ainty dish,', 'inty dish, ', 'nty dish, T', 'ty dish, To', 'y dish, To ', ' dish, To s', 'dish, To se', 'ish, To set', 'sh, To set ', 'h, To set b', ', To set be', ' To set bef', 'To set befo', 'o set befor', ' set before', 'set before ', 'et before t', 't before th', ' before the', 'before the ', 'efore the k', 'fore the ki', 'ore the kin', 're the king', 'e the king.', ' the king. ', 'the king. T', 'he king. Th', 'e king. The', ' king. The ', 'king. The k', 'ing. The ki', 'ng. The kin', 'g. The king', '. The king ', ' The king w', 'The king wa', 'he king was', 'e king was ', ' king was i', 'king was in', 'ing was in ', 'ng was in h', 'g was in hi', ' was in his', 'was in his ', 'as in his c', 's in his co', ' in his cou', 'in his coun', 'n his count', ' his counti', 'his countin', 'is counting', 's counting ', ' counting h', 'counting ho', 'ounting hou', 'unting hous', 'nting house', 'ting house,', 'ing house, ', 'ng house, C', 'g house, Co', ' house, Cou', 'house, Coun', 'ouse, Count', 'use, Counti', 'se, Countin', 'e, Counting', ', Counting ', ' Counting o', 'Counting ou', 'ounting out', 'unting out ', 'nting out h', 'ting out hi', 'ing out his', 'ng out his ', 'g out his m', ' out his mo', 'out his mon', 'ut his mone', 't his money', ' his money;', 'his money; ', 'is money; T', 's money; Th', ' money; The', 'money; The ', 'oney; The q', 'ney; The qu', 'ey; The que', 'y; The quee', '; The queen', ' The queen ', 'The queen w', 'he queen wa', 'e queen was', ' queen was ', 'queen was i', 'ueen was in', 'een was in ', 'en was in t', 'n was in th', ' was in the', 'was in the ', 'as in the p', 's in the pa', ' in the par', 'in the parl', 'n the parlo', ' the parlou', 'the parlour', 'he parlour,', 'e parlour, ', ' parlour, E', 'parlour, Ea', 'arlour, Eat', 'rlour, Eati', 'lour, Eatin', 'our, Eating', 'ur, Eating ', 'r, Eating b', ', Eating br', ' Eating bre', 'Eating brea', 'ating bread', 'ting bread ', 'ing bread a', 'ng bread an', 'g bread and', ' bread and ', 'bread and h', 'read and ho', 'ead and hon', 'ad and hone', 'd and honey', ' and honey.', 'and honey. ', 'nd honey. T', 'd honey. Th', ' honey. The', 'honey. The ', 'oney. The m', 'ney. The ma', 'ey. The mai', 'y. The maid', '. The maid ', ' The maid w', 'The maid wa', 'he maid was', 'e maid was ', ' maid was i', 'maid was in', 'aid was in ', 'id was in t', 'd was in th', ' was in the', 'was in the ', 'as in the g', 's in the ga', ' in the gar', 'in the gard', 'n the garde', ' the garden', 'the garden,', 'he garden, ', 'e garden, H', ' garden, Ha', 'garden, Han', 'arden, Hang', 'rden, Hangi', 'den, Hangin', 'en, Hanging', 'n, Hanging ', ', Hanging o', ' Hanging ou', 'Hanging out', 'anging out ', 'nging out t', 'ging out th', 'ing out the', 'ng out the ', 'g out the c', ' out the cl', 'out the clo', 'ut the clot', 't the cloth', ' the clothe', 'the clothes', 'he clothes,', 'e clothes, ', ' clothes, W', 'clothes, Wh', 'lothes, Whe', 'othes, When', 'thes, When ', 'hes, When d', 'es, When do', 's, When dow', ', When down', ' When down ', 'When down c', 'hen down ca', 'en down cam', 'n down came', ' down came ', 'down came a', 'own came a ', 'wn came a b', 'n came a bl', ' came a bla', 'came a blac', 'ame a black', 'me a blackb', 'e a blackbi', ' a blackbir', 'a blackbird', ' blackbird ', 'blackbird A', 'lackbird An', 'ackbird And', 'ckbird And ', 'kbird And p', 'bird And pe', 'ird And pec', 'rd And peck', 'd And pecke', ' And pecked', 'And pecked ', 'nd pecked o', 'd pecked of', ' pecked off', 'pecked off ', 'ecked off h', 'cked off he', 'ked off her', 'ed off her ', 'd off her n', ' off her no', 'off her nos', 'ff her nose', 'f her nose.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbIojlX89XWe",
        "colab_type": "code",
        "outputId": "17b72900-3454-4eb0-a4f8-832b8cbe5544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# integer encode sequences of characters\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print (chars)\n",
        "\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "print (mapping)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', \"'\", ',', '.', ';', 'A', 'B', 'C', 'E', 'F', 'H', 'S', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'w', 'x', 'y']\n",
            "{'\\n': 0, ' ': 1, \"'\": 2, ',': 3, '.': 4, ';': 5, 'A': 6, 'B': 7, 'C': 8, 'E': 9, 'F': 10, 'H': 11, 'S': 12, 'T': 13, 'W': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'k': 24, 'l': 25, 'm': 26, 'n': 27, 'o': 28, 'p': 29, 'q': 30, 'r': 31, 's': 32, 't': 33, 'u': 34, 'w': 35, 'x': 36, 'y': 37}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rfaEfv095Os",
        "colab_type": "code",
        "outputId": "7735f6a6-8302-422f-d74a-cc1af18e726a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "sequences = list()\n",
        "for line in lines:\n",
        "\t# integer encode line\n",
        "\tencoded_seq = [mapping[char] for char in line]\n",
        "\t# store\n",
        "\tsequences.append(encoded_seq)\n",
        "\n",
        "print ((type(sequences))) \n",
        "print (sequences[0])    # int sequence\n",
        "print (sequences[397])\n",
        "print (sequences[398])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[12, 23, 27, 21, 1, 15, 1, 32, 28, 27, 21]\n",
            "[20, 20, 1, 22, 19, 31, 1, 27, 28, 32, 19]\n",
            "[20, 1, 22, 19, 31, 1, 27, 28, 32, 19, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4--ybYlE9-eO",
        "colab_type": "code",
        "outputId": "64cffce9-386e-4f55-b036-120047f0367c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(mapping)\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm_wenId-C75",
        "colab_type": "text"
      },
      "source": [
        "Split Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmLCFS41-MVX",
        "colab_type": "code",
        "outputId": "4c624c0c-c0ab-4d66-bb73-e88c9eaa496d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# separate into input and output\n",
        "sequences = array(sequences)\n",
        "print (sequences.shape)\n",
        "\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "print (X.shape)\n",
        "print (y.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(399, 11)\n",
            "(399, 10)\n",
            "(399,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSS88Iwu-4QY",
        "colab_type": "code",
        "outputId": "392c62df-2195-4315-92ab-4d653b14040f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
        "print (sequences[0].shape)   # (10,38)\n",
        "print (sequences[398].shape) # (10,38)\n",
        "\n",
        "X = array(sequences)\n",
        "print (X.shape) # (399, 10, 38)\n",
        "\n",
        "print (y.shape) # (399,)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "print (y.shape) # (399, 38)\n",
        "print (y[0])  # g -> 21th one-hot"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 38)\n",
            "(10, 38)\n",
            "(399, 10, 38)\n",
            "(399,)\n",
            "(399, 38)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp0hLgiCjAtG",
        "colab_type": "code",
        "outputId": "ed75c82f-e92b-4162-e927-93f07ebd4310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print (X.shape[1])\n",
        "print (X.shape[2])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBbBnd8D_or3",
        "colab_type": "code",
        "outputId": "759dacb4-e601-4b72-9fa2-70939aef6159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 75)                34200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                2888      \n",
            "=================================================================\n",
            "Total params: 37,088\n",
            "Trainable params: 37,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPCGc3B__tXe",
        "colab_type": "code",
        "outputId": "0f326e19-8a44-4397-8866-a0c9f50bd5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "print (X.shape) # (399, 10, 38)\n",
        "print (y.shape) # (399, 38)\n",
        "model.fit(X, y, epochs=100, verbose=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(399, 10, 38)\n",
            "(399, 38)\n",
            "Train on 399 samples\n",
            "Epoch 1/100\n",
            "399/399 - 3s - loss: 3.6088 - accuracy: 0.0977\n",
            "Epoch 2/100\n",
            "399/399 - 0s - loss: 3.4952 - accuracy: 0.1880\n",
            "Epoch 3/100\n",
            "399/399 - 0s - loss: 3.1796 - accuracy: 0.1905\n",
            "Epoch 4/100\n",
            "399/399 - 0s - loss: 3.0541 - accuracy: 0.1905\n",
            "Epoch 5/100\n",
            "399/399 - 0s - loss: 3.0054 - accuracy: 0.1905\n",
            "Epoch 6/100\n",
            "399/399 - 0s - loss: 2.9923 - accuracy: 0.1905\n",
            "Epoch 7/100\n",
            "399/399 - 0s - loss: 2.9720 - accuracy: 0.1905\n",
            "Epoch 8/100\n",
            "399/399 - 0s - loss: 2.9629 - accuracy: 0.1905\n",
            "Epoch 9/100\n",
            "399/399 - 0s - loss: 2.9498 - accuracy: 0.1905\n",
            "Epoch 10/100\n",
            "399/399 - 0s - loss: 2.9349 - accuracy: 0.1905\n",
            "Epoch 11/100\n",
            "399/399 - 0s - loss: 2.9178 - accuracy: 0.1905\n",
            "Epoch 12/100\n",
            "399/399 - 0s - loss: 2.9009 - accuracy: 0.1930\n",
            "Epoch 13/100\n",
            "399/399 - 0s - loss: 2.8756 - accuracy: 0.1905\n",
            "Epoch 14/100\n",
            "399/399 - 0s - loss: 2.8618 - accuracy: 0.1905\n",
            "Epoch 15/100\n",
            "399/399 - 0s - loss: 2.8451 - accuracy: 0.2431\n",
            "Epoch 16/100\n",
            "399/399 - 0s - loss: 2.8144 - accuracy: 0.1905\n",
            "Epoch 17/100\n",
            "399/399 - 0s - loss: 2.7843 - accuracy: 0.2456\n",
            "Epoch 18/100\n",
            "399/399 - 0s - loss: 2.7585 - accuracy: 0.1930\n",
            "Epoch 19/100\n",
            "399/399 - 0s - loss: 2.7194 - accuracy: 0.2531\n",
            "Epoch 20/100\n",
            "399/399 - 0s - loss: 2.6734 - accuracy: 0.2406\n",
            "Epoch 21/100\n",
            "399/399 - 0s - loss: 2.6322 - accuracy: 0.2481\n",
            "Epoch 22/100\n",
            "399/399 - 0s - loss: 2.5896 - accuracy: 0.2632\n",
            "Epoch 23/100\n",
            "399/399 - 0s - loss: 2.5527 - accuracy: 0.2657\n",
            "Epoch 24/100\n",
            "399/399 - 0s - loss: 2.5092 - accuracy: 0.3108\n",
            "Epoch 25/100\n",
            "399/399 - 0s - loss: 2.4765 - accuracy: 0.3033\n",
            "Epoch 26/100\n",
            "399/399 - 0s - loss: 2.4276 - accuracy: 0.3308\n",
            "Epoch 27/100\n",
            "399/399 - 0s - loss: 2.3875 - accuracy: 0.3484\n",
            "Epoch 28/100\n",
            "399/399 - 0s - loss: 2.3506 - accuracy: 0.3108\n",
            "Epoch 29/100\n",
            "399/399 - 0s - loss: 2.3177 - accuracy: 0.3409\n",
            "Epoch 30/100\n",
            "399/399 - 0s - loss: 2.2766 - accuracy: 0.3484\n",
            "Epoch 31/100\n",
            "399/399 - 0s - loss: 2.2343 - accuracy: 0.3509\n",
            "Epoch 32/100\n",
            "399/399 - 0s - loss: 2.1916 - accuracy: 0.3584\n",
            "Epoch 33/100\n",
            "399/399 - 0s - loss: 2.1600 - accuracy: 0.3935\n",
            "Epoch 34/100\n",
            "399/399 - 0s - loss: 2.1303 - accuracy: 0.3860\n",
            "Epoch 35/100\n",
            "399/399 - 0s - loss: 2.0932 - accuracy: 0.3810\n",
            "Epoch 36/100\n",
            "399/399 - 0s - loss: 2.0499 - accuracy: 0.4060\n",
            "Epoch 37/100\n",
            "399/399 - 0s - loss: 1.9878 - accuracy: 0.4586\n",
            "Epoch 38/100\n",
            "399/399 - 0s - loss: 1.9512 - accuracy: 0.4461\n",
            "Epoch 39/100\n",
            "399/399 - 0s - loss: 1.9181 - accuracy: 0.4687\n",
            "Epoch 40/100\n",
            "399/399 - 0s - loss: 1.8780 - accuracy: 0.4787\n",
            "Epoch 41/100\n",
            "399/399 - 0s - loss: 1.8280 - accuracy: 0.4862\n",
            "Epoch 42/100\n",
            "399/399 - 0s - loss: 1.7900 - accuracy: 0.5063\n",
            "Epoch 43/100\n",
            "399/399 - 0s - loss: 1.7533 - accuracy: 0.4987\n",
            "Epoch 44/100\n",
            "399/399 - 0s - loss: 1.7120 - accuracy: 0.5313\n",
            "Epoch 45/100\n",
            "399/399 - 0s - loss: 1.6718 - accuracy: 0.5464\n",
            "Epoch 46/100\n",
            "399/399 - 0s - loss: 1.6335 - accuracy: 0.5363\n",
            "Epoch 47/100\n",
            "399/399 - 0s - loss: 1.6008 - accuracy: 0.5714\n",
            "Epoch 48/100\n",
            "399/399 - 0s - loss: 1.5625 - accuracy: 0.5789\n",
            "Epoch 49/100\n",
            "399/399 - 0s - loss: 1.5361 - accuracy: 0.5739\n",
            "Epoch 50/100\n",
            "399/399 - 0s - loss: 1.4804 - accuracy: 0.6090\n",
            "Epoch 51/100\n",
            "399/399 - 0s - loss: 1.4385 - accuracy: 0.6090\n",
            "Epoch 52/100\n",
            "399/399 - 0s - loss: 1.4013 - accuracy: 0.6341\n",
            "Epoch 53/100\n",
            "399/399 - 0s - loss: 1.3700 - accuracy: 0.6266\n",
            "Epoch 54/100\n",
            "399/399 - 0s - loss: 1.3658 - accuracy: 0.6341\n",
            "Epoch 55/100\n",
            "399/399 - 0s - loss: 1.2862 - accuracy: 0.6617\n",
            "Epoch 56/100\n",
            "399/399 - 0s - loss: 1.2646 - accuracy: 0.6617\n",
            "Epoch 57/100\n",
            "399/399 - 0s - loss: 1.2244 - accuracy: 0.7018\n",
            "Epoch 58/100\n",
            "399/399 - 0s - loss: 1.1944 - accuracy: 0.7018\n",
            "Epoch 59/100\n",
            "399/399 - 0s - loss: 1.1403 - accuracy: 0.7243\n",
            "Epoch 60/100\n",
            "399/399 - 0s - loss: 1.1304 - accuracy: 0.7268\n",
            "Epoch 61/100\n",
            "399/399 - 0s - loss: 1.0813 - accuracy: 0.7744\n",
            "Epoch 62/100\n",
            "399/399 - 0s - loss: 1.0322 - accuracy: 0.7719\n",
            "Epoch 63/100\n",
            "399/399 - 0s - loss: 1.0016 - accuracy: 0.7945\n",
            "Epoch 64/100\n",
            "399/399 - 0s - loss: 0.9658 - accuracy: 0.7895\n",
            "Epoch 65/100\n",
            "399/399 - 0s - loss: 0.9285 - accuracy: 0.8170\n",
            "Epoch 66/100\n",
            "399/399 - 0s - loss: 0.9215 - accuracy: 0.8045\n",
            "Epoch 67/100\n",
            "399/399 - 0s - loss: 0.8735 - accuracy: 0.8271\n",
            "Epoch 68/100\n",
            "399/399 - 0s - loss: 0.8527 - accuracy: 0.8321\n",
            "Epoch 69/100\n",
            "399/399 - 0s - loss: 0.8245 - accuracy: 0.8647\n",
            "Epoch 70/100\n",
            "399/399 - 0s - loss: 0.8001 - accuracy: 0.8571\n",
            "Epoch 71/100\n",
            "399/399 - 0s - loss: 0.7569 - accuracy: 0.8722\n",
            "Epoch 72/100\n",
            "399/399 - 0s - loss: 0.7338 - accuracy: 0.8697\n",
            "Epoch 73/100\n",
            "399/399 - 0s - loss: 0.7164 - accuracy: 0.8797\n",
            "Epoch 74/100\n",
            "399/399 - 0s - loss: 0.6670 - accuracy: 0.9023\n",
            "Epoch 75/100\n",
            "399/399 - 0s - loss: 0.6527 - accuracy: 0.9123\n",
            "Epoch 76/100\n",
            "399/399 - 0s - loss: 0.6407 - accuracy: 0.8972\n",
            "Epoch 77/100\n",
            "399/399 - 0s - loss: 0.5991 - accuracy: 0.9198\n",
            "Epoch 78/100\n",
            "399/399 - 0s - loss: 0.5672 - accuracy: 0.9373\n",
            "Epoch 79/100\n",
            "399/399 - 0s - loss: 0.5638 - accuracy: 0.9348\n",
            "Epoch 80/100\n",
            "399/399 - 0s - loss: 0.5411 - accuracy: 0.9449\n",
            "Epoch 81/100\n",
            "399/399 - 0s - loss: 0.5279 - accuracy: 0.9398\n",
            "Epoch 82/100\n",
            "399/399 - 0s - loss: 0.4879 - accuracy: 0.9624\n",
            "Epoch 83/100\n",
            "399/399 - 0s - loss: 0.4683 - accuracy: 0.9674\n",
            "Epoch 84/100\n",
            "399/399 - 0s - loss: 0.4475 - accuracy: 0.9724\n",
            "Epoch 85/100\n",
            "399/399 - 0s - loss: 0.4289 - accuracy: 0.9699\n",
            "Epoch 86/100\n",
            "399/399 - 0s - loss: 0.4168 - accuracy: 0.9724\n",
            "Epoch 87/100\n",
            "399/399 - 0s - loss: 0.3927 - accuracy: 0.9749\n",
            "Epoch 88/100\n",
            "399/399 - 0s - loss: 0.3883 - accuracy: 0.9749\n",
            "Epoch 89/100\n",
            "399/399 - 0s - loss: 0.3681 - accuracy: 0.9774\n",
            "Epoch 90/100\n",
            "399/399 - 0s - loss: 0.3425 - accuracy: 0.9825\n",
            "Epoch 91/100\n",
            "399/399 - 0s - loss: 0.3422 - accuracy: 0.9799\n",
            "Epoch 92/100\n",
            "399/399 - 0s - loss: 0.3266 - accuracy: 0.9825\n",
            "Epoch 93/100\n",
            "399/399 - 0s - loss: 0.3100 - accuracy: 0.9875\n",
            "Epoch 94/100\n",
            "399/399 - 0s - loss: 0.2943 - accuracy: 0.9850\n",
            "Epoch 95/100\n",
            "399/399 - 0s - loss: 0.2828 - accuracy: 0.9875\n",
            "Epoch 96/100\n",
            "399/399 - 0s - loss: 0.2720 - accuracy: 0.9875\n",
            "Epoch 97/100\n",
            "399/399 - 0s - loss: 0.2655 - accuracy: 0.9850\n",
            "Epoch 98/100\n",
            "399/399 - 0s - loss: 0.2532 - accuracy: 0.9875\n",
            "Epoch 99/100\n",
            "399/399 - 0s - loss: 0.2413 - accuracy: 0.9900\n",
            "Epoch 100/100\n",
            "399/399 - 0s - loss: 0.2322 - accuracy: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67df150470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHH38diEAnov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYSslXnUjX9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the mapping\n",
        "dump(mapping, open('mapping.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng8OH_7boYHs",
        "colab_type": "text"
      },
      "source": [
        "### Generate Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv903tE0BCf9",
        "colab_type": "text"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpJwcYpjBskV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kteDW8QSosc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence of characters with a language model\n",
        "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of characters\n",
        "\tfor _ in range(n_chars):\n",
        "\t\t# encode the characters as integers\n",
        "\t\tencoded = [mapping[char] for char in in_text]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# one hot encode\n",
        "\t\tencoded = to_categorical(encoded, num_classes=len(mapping))\n",
        "\t\t#encoded = encoded.reshape(1, encoded.shape[0], encoded.shape[1])\n",
        "\t\t# predict character\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# reverse map integer to character\n",
        "\t\tout_char = ''\n",
        "\t\tfor char, index in mapping.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_char = char\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += char\n",
        "\treturn in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5t-yBOmjY3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model\n",
        "model = tf.keras.models.load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyyRwfXJogYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the mapping\n",
        "mapping = pickle.load(open('mapping.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-JoYPDoxAb-",
        "colab_type": "code",
        "outputId": "b3ec674c-4cc7-47ad-cd2e-edbff8db4282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# test start of rhyme\n",
        "print(generate_seq(model, mapping, 10, 'Sing a son', 20))\n",
        "# test mid-line\n",
        "print(generate_seq(model, mapping, 10, 'king was i', 20))\n",
        "# test not in original\n",
        "print(generate_seq(model, mapping, 10, 'hello worl', 20))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sing a song of sixpence, A poc\n",
            "king was in his counting house\n",
            "hello worlke Fesk Tof e effl o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O3qLF_PCLTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}